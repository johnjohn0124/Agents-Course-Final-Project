{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e470db5-d057-4327-8a6e-f25711cbc476",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "To train a model with implicit language Q-learning.\n",
    "\n",
    "To keep things fair, sparse zero-one rewards will be used as signal.\n",
    "\n",
    "## Inputs:\n",
    "\n",
    "- Offline dataset from the task of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e52a59-379d-4ede-81f9-06bdfae55b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['HF_HOME'] = '/home/seobrien/.cache/'\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from ilql_utils import train_ilql\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b77398ed-8d16-487e-9fce-f0f21174b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './configs/ilql/default.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "686b75a2-1232-4ec1-b65f-c3e35ec112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7f9d918-8861-40db-959f-59a9023c3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.saving.save_basedir = config.saving.save_basedir.format(task=config.task)\n",
    "config.data_path = config.data_path.format(task=config.task)\n",
    "\n",
    "config.saving.save_dir = os.path.join(config.saving.save_basedir,\n",
    "                            config.run_group_name,\n",
    "                            config.run_name)\n",
    "\n",
    "os.makedirs(config.saving.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f2fb328-6c13-4c94-9320-76283b337e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step -- format 20Q data according to what we expect to take in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8078d15-c014-4730-991a-5f0ad99dc714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared!\n"
     ]
    }
   ],
   "source": [
    "# code for generating held out cities\n",
    "task = 'twenty-questions'\n",
    "\n",
    "held_out_secrets_path = f'input_data/{task}/held_out_secrets.json'\n",
    "filtered_train_path = f'input_data/{task}/train_transformed.json'\n",
    "filtered_eval_path = f'input_data/{task}/eval_transformed.json'\n",
    "\n",
    "def transform_datapoint(d):\n",
    "    turns = []\n",
    "    for line in d['lines']:\n",
    "        if '? ' not in line:\n",
    "            return None\n",
    "        try:\n",
    "            clauses = line.split('? ')\n",
    "            q_str = '? '.join(clauses[:-1]) + '?'\n",
    "            a_str = clauses[-1]\n",
    "        except:\n",
    "            print(line)\n",
    "            raise ValueError()\n",
    "        \n",
    "        turns.extend([q_str, a_str])\n",
    "    new_d = {\n",
    "        'turns': turns, \n",
    "        'secret': d['word'][0] if isinstance(d['word'], list) else d['word'],\n",
    "        'guessed': d['correct']\n",
    "    }\n",
    "    return new_d\n",
    "    \n",
    "    \n",
    "\n",
    "with open(f'./input_data/{task}/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(f'./input_data/{task}/eval.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "\n",
    "if os.path.exists(held_out_secrets_path):\n",
    "    with open(f'./input_data/{task}/held_out_secrets.json', 'r') as f:\n",
    "        held_out_secrets = json.load(f)\n",
    "else:\n",
    "    \n",
    "    words_train = Counter([sorted(d['word'])[0] if isinstance(d['word'], list) else d['word'] for d in train_data])\n",
    "    words_eval = Counter([sorted(d['word'])[0] if isinstance(d['word'], list) else d['word'] for d in eval_data])\n",
    "    \n",
    "    secrets = list(set(words_eval.keys()))\n",
    "    random.seed(42)\n",
    "    random.shuffle(secrets)\n",
    "    held_out_secrets = secrets[:10]\n",
    "\n",
    "    with open(held_out_secrets_path, 'w') as f:\n",
    "        json.dump(held_out_secrets, f)\n",
    "\n",
    "# hold out some cities to test for generalization\n",
    "\n",
    "if not os.path.exists(filtered_train_path):\n",
    "    filtered_train_data = [t for t in train_data if t['word'] not in held_out_secrets and t['word'][0] not in held_out_secrets]\n",
    "    filtered_train_data = [transform_datapoint(d) for d in filtered_train_data]\n",
    "    \n",
    "    with open(filtered_train_path, 'w') as f:\n",
    "        json.dump(filtered_train_data, f)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(filtered_eval_path):\n",
    "    filtered_eval_data = [transform_datapoint(d) for d in eval_data]\n",
    "    with open(filtered_eval_path, 'w') as f:\n",
    "        json.dump(filtered_eval_data, f)\n",
    "\n",
    "\n",
    "with open(filtered_train_path, 'r') as f:\n",
    "    train_transformed = json.load(f)\n",
    "\n",
    "with open(filtered_eval_path, 'r') as f:\n",
    "    eval_transformed = json.load(f)\n",
    "\n",
    "print('Data prepared!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fa6b2-a7f6-4ac0-9291-a5a670c5a5ec",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb9b4766-0248-4a93-9d38-32478e34e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2776.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2888.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "TRAIN DATA LENGTH: 1000\n",
      "VAL DATA LENGTH: 100\n",
      "##################################################\n",
      "EXAMPLE TRAJECTORY:\n",
      "##################################################\n",
      "('user: Is the object an animal?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object man-made?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a mineral?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a plant?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a tree?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a fruit?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a flower?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a vegetable?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a root vegetable?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object an ornamental vegetable?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object an edible berry?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a leafy green vegetable?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object spinach?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object kale?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object kale Caesar?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object cabbage?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object Swiss chard?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.')\n",
      "##################################################\n",
      "BEFORE LOADING MODEL\n",
      "Num GPUs available: 1\n",
      "CUDA_VISIBLE_DEVICES 1\n",
      "Total GPU memory: 23.70 GB\n",
      "Allocated GPU memory: 3.82 GB\n",
      "Free GPU memory: 19.88 GB\n",
      "##################################################\n",
      "LOADING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seobrien/miniconda3/envs/agents/lib/python3.13/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 18052.7148:   0%|▎                                                                                    | 4/1000 [00:00<00:28, 35.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "EXAMPLE TRAJECTORY:\n",
      "('user: Is it larger than a breadbox?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a tennis ball?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it smaller than a marble?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it larger than a walnut?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a pea?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a penny?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a tennis ball ball?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it smaller than a coin?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a tennis ball ball?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a marble?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a wooden chopstick?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a wooden pencil?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a wooden chopstick handle?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a wooden pen?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it smaller than a wooden utensil?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a wooden spoon?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a wooden fork?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object made of metal?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a small container?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a keychain?\\n'\n",
      " 'assistant: No.')\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 23239.4062: 100%|██████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 61.64it/s]\n",
      "Loss: 13603.7998: 100%|██████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 62.75it/s]\n",
      "Loss: 8735.9316: 100%|███████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 61.80it/s]\n",
      "Loss: 21545.1797: 100%|██████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 62.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at ./checkpoints/ilql/twenty-questions/DEBUG-GROUP/DEBUG-RUN-NAME/final_checkpoint\n"
     ]
    }
   ],
   "source": [
    "train_ilql(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a1ab2bc-b6f9-4467-b6a5-c47e55753c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66975582-18af-474e-a543-e53466661c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cfcf7-34ef-4978-bebf-6fcd5b8722f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720bc9b-94fa-4db9-9828-4f94a6403b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
