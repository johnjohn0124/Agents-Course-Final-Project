{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e470db5-d057-4327-8a6e-f25711cbc476",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "To train a model with implicit language Q-learning.\n",
    "\n",
    "To keep things fair, sparse zero-one rewards will be used as signal.\n",
    "\n",
    "## Inputs:\n",
    "\n",
    "- Offline dataset from the task of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e52a59-379d-4ede-81f9-06bdfae55b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['HF_HOME'] = '/teamspace/studios/this_studio/Agents-Course-Final-Project/.cache/'\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from ilql_utils import train_ilql\n",
    "from ilql_eval import run_evaluations, compute_cross_run_metrics\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b77398ed-8d16-487e-9fce-f0f21174b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './configs/ilql/default.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "686b75a2-1232-4ec1-b65f-c3e35ec112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7f9d918-8861-40db-959f-59a9023c3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.saving.save_basedir = config.saving.save_basedir.format(task=config.task)\n",
    "config.data_path = config.data_path.format(task=config.task)\n",
    "\n",
    "config.saving.save_dir = os.path.join(config.saving.save_basedir,\n",
    "                            config.run_group_name,\n",
    "                            config.run_name)\n",
    "\n",
    "os.makedirs(config.saving.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2fb328-6c13-4c94-9320-76283b337e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step -- format 20Q data according to what we expect to take in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8078d15-c014-4730-991a-5f0ad99dc714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared!\n"
     ]
    }
   ],
   "source": [
    "# code for generating held out cities\n",
    "task = 'twenty-questions'\n",
    "\n",
    "held_out_secrets_path = f'input_data/{task}/held_out_secrets.json'\n",
    "filtered_train_path = f'input_data/{task}/train_transformed.json'\n",
    "filtered_eval_path = f'input_data/{task}/eval_transformed.json'\n",
    "\n",
    "def transform_datapoint(d):\n",
    "    turns = []\n",
    "    for line in d['lines']:\n",
    "        if '? ' not in line:\n",
    "            return None\n",
    "        try:\n",
    "            clauses = line.split('? ')\n",
    "            q_str = '? '.join(clauses[:-1]) + '?'\n",
    "            a_str = clauses[-1]\n",
    "        except:\n",
    "            print(line)\n",
    "            raise ValueError()\n",
    "        \n",
    "        turns.extend([q_str, a_str])\n",
    "    new_d = {\n",
    "        'turns': turns, \n",
    "        'secret': d['word'][0] if isinstance(d['word'], list) else d['word'],\n",
    "        'guessed': d['correct']\n",
    "    }\n",
    "    return new_d\n",
    "    \n",
    "    \n",
    "\n",
    "with open(f'./input_data/{task}/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(f'./input_data/{task}/eval.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "\n",
    "if os.path.exists(held_out_secrets_path):\n",
    "    with open(f'./input_data/{task}/held_out_secrets.json', 'r') as f:\n",
    "        held_out_secrets = json.load(f)\n",
    "else:\n",
    "    \n",
    "    words_train = Counter([sorted(d['word'])[0] if isinstance(d['word'], list) else d['word'] for d in train_data])\n",
    "    words_eval = Counter([sorted(d['word'])[0] if isinstance(d['word'], list) else d['word'] for d in eval_data])\n",
    "    \n",
    "    secrets = list(set(words_eval.keys()))\n",
    "    random.seed(42)\n",
    "    random.shuffle(secrets)\n",
    "    held_out_secrets = secrets[:10]\n",
    "\n",
    "    with open(held_out_secrets_path, 'w') as f:\n",
    "        json.dump(held_out_secrets, f)\n",
    "\n",
    "# hold out some cities to test for generalization\n",
    "\n",
    "if not os.path.exists(filtered_train_path):\n",
    "    filtered_train_data = [t for t in train_data if t['word'] not in held_out_secrets and t['word'][0] not in held_out_secrets]\n",
    "    filtered_train_data = [transform_datapoint(d) for d in filtered_train_data]\n",
    "    \n",
    "    with open(filtered_train_path, 'w') as f:\n",
    "        json.dump(filtered_train_data, f)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(filtered_eval_path):\n",
    "    filtered_eval_data = [transform_datapoint(d) for d in eval_data]\n",
    "    with open(filtered_eval_path, 'w') as f:\n",
    "        json.dump(filtered_eval_data, f)\n",
    "\n",
    "\n",
    "with open(filtered_train_path, 'r') as f:\n",
    "    train_transformed = json.load(f)\n",
    "\n",
    "with open(filtered_eval_path, 'r') as f:\n",
    "    eval_transformed = json.load(f)\n",
    "\n",
    "print('Data prepared!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fa6b2-a7f6-4ac0-9291-a5a670c5a5ec",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb9b4766-0248-4a93-9d38-32478e34e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 938.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 990.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "TRAIN DATA LENGTH: 100\n",
      "VAL DATA LENGTH: 100\n",
      "##################################################\n",
      "EXAMPLE TRAJECTORY:\n",
      "##################################################\n",
      "('user: Is the object an animal?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object man-made?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a mineral?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a plant?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a tree?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a fruit?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a flower?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a vegetable?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object a root vegetable?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object an ornamental vegetable?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object an edible berry?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object a leafy green vegetable?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is the object spinach?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object kale?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object kale Caesar?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object cabbage?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object Swiss chard?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is the object romaine lettuce?\\n'\n",
      " 'assistant: No.\\n')\n",
      "##################################################\n",
      "BEFORE LOADING MODEL\n",
      "Num GPUs available: 1\n",
      "CUDA_VISIBLE_DEVICES None\n",
      "Total GPU memory: 14.75 GB\n",
      "Allocated GPU memory: 0.02 GB\n",
      "Free GPU memory: 14.73 GB\n",
      "##################################################\n",
      "LOADING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL LOADED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (6.9s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/Agents-Course-Final-Project/wandb/run-20250313_001340-s8omzq9z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/johnfang1473-uc-san-diego/agents/runs/s8omzq9z' target=\"_blank\">gpt2-xl_42_100</a></strong> to <a href='https://wandb.ai/johnfang1473-uc-san-diego/agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/johnfang1473-uc-san-diego/agents' target=\"_blank\">https://wandb.ai/johnfang1473-uc-san-diego/agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/johnfang1473-uc-san-diego/agents/runs/s8omzq9z' target=\"_blank\">https://wandb.ai/johnfang1473-uc-san-diego/agents/runs/s8omzq9z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "EXAMPLE TRAJECTORY:\n",
      "('user: Is it an animal?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it an inanimate object?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it man-made?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a tool?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a piece of technology?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a piece of furniture?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it an item of clothing?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a kitchen appliance?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a household item?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a decoration?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a toy?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it something used in the outdoors?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a recreational vehicle?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a sporting equipment?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a bat?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a glove?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a ball?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a soccer ball?\\n'\n",
      " 'assistant: No.\\n'\n",
      " 'user: Is it a sports equipment ball?\\n'\n",
      " 'assistant: Yes.\\n'\n",
      " 'user: Is it a volleyball?\\n'\n",
      " 'assistant: No.\\n')\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 241.5545: 100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n",
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n",
      "Loss: 255.5099: 100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n",
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n",
      "Loss: 228.4615: 100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n",
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n",
      "Loss: 237.5196: 100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n",
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at ./checkpoints/twenty-questions/ilql/DEBUG-GROUP/gpt2-xl_42_100/final_checkpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cql_loss</td><td>▃▃▃▂▂▂█▄▇▂▃▃▆▂▂▃▃▂▃▃▅▇▃▂█▂▂▃▃▃▁▃▄▄▃▃▂▃▂▂</td></tr><tr><td>cql_loss_val</td><td>█▃▁▂</td></tr><tr><td>expectile_loss</td><td>▄▂▄▇▃▃▃▁▁█▂▃▄▃▄▂▂▃▃▂▄▂▃▂▂▄▁▅▅▂▃▂▃▂▃▄▃▃▃▃</td></tr><tr><td>expectile_loss_val</td><td>█▂▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>loss</td><td>▅▂▄▄▅▄▄▄▆▃▄▁▃▄▆▆▃▅▇▂▆▂▅▅▃▄█▇▅▃▃▃▁▃▂▄▃▃▃▃</td></tr><tr><td>loss_val</td><td>█▂▁▁</td></tr><tr><td>lr</td><td>██████▇▇▇▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mc_loss</td><td>▄▃▃▃▃▄▄▂▅▆▂▆▃▂▁▂▁▂▁▁▆▁▂█▁▁▇▁▇▂▂▁█▁▇▁▁▁█▂</td></tr><tr><td>mc_loss_val</td><td>█▂▁▁</td></tr><tr><td>q_loss</td><td>▇▄▅▄▄▃▅▄▂▃▃▂▃▄▁▂▃▃▅▃▄▂█▃▆▄▃▃▄▃▅▅▃▃▃▄▂▆▄▄</td></tr><tr><td>q_loss_val</td><td>█▂▁▁</td></tr><tr><td>q_value_mean</td><td>▄▅▃▃▇▅▄▅▃▆▆▄▁▇▇▆▄▇▅▅█▆▇▅▇▅▃▇▅▆█▇█▆▇█▂▇▂█</td></tr><tr><td>q_value_mean_val</td><td>▁▆██</td></tr><tr><td>v_acc</td><td>▆▄▅▆▄▇▇▇▂▇▇▅█▇▃▇█▁▁██▇▇██▂████▇▇█▂▇▁███▁</td></tr><tr><td>v_acc_val</td><td>▁███</td></tr><tr><td>v_loss</td><td>▃▄▄▄▃▃▃▆▁▃▄▄▃▅▄▃▃▂▄▃▂▅▅▅▂▂▆▅▃▆▄█▄▅▁▃▅▆▃▅</td></tr><tr><td>v_loss_val</td><td>█▂▁▁</td></tr><tr><td>v_value_mean</td><td>█▆▇▆█▇▇▄▇▅▄▅▇▅▄▂▂▃▃▅▄▂▁▂▄▁▂▂▁▃▂▃▄▂▂▂▄▁▁▄</td></tr><tr><td>v_value_mean_val</td><td>█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cql_loss</td><td>0.94141</td></tr><tr><td>cql_loss_val</td><td>0.83375</td></tr><tr><td>expectile_loss</td><td>54.51488</td></tr><tr><td>expectile_loss_val</td><td>53.72224</td></tr><tr><td>global_step</td><td>400</td></tr><tr><td>loss</td><td>237.51958</td></tr><tr><td>loss_val</td><td>233.8264</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mc_loss</td><td>0.82812</td></tr><tr><td>mc_loss_val</td><td>0.65648</td></tr><tr><td>q_loss</td><td>183</td></tr><tr><td>q_loss_val</td><td>180.10001</td></tr><tr><td>q_value_mean</td><td>-13.1875</td></tr><tr><td>q_value_mean_val</td><td>-13.11625</td></tr><tr><td>v_acc</td><td>0.08738</td></tr><tr><td>v_acc_val</td><td>0.65124</td></tr><tr><td>v_loss</td><td>54.51488</td></tr><tr><td>v_loss_val</td><td>53.72224</td></tr><tr><td>v_value_mean</td><td>-0.24414</td></tr><tr><td>v_value_mean_val</td><td>-0.25336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gpt2-xl_42_100</strong> at: <a href='https://wandb.ai/johnfang1473-uc-san-diego/agents/runs/s8omzq9z' target=\"_blank\">https://wandb.ai/johnfang1473-uc-san-diego/agents/runs/s8omzq9z</a><br> View project at: <a href='https://wandb.ai/johnfang1473-uc-san-diego/agents' target=\"_blank\">https://wandb.ai/johnfang1473-uc-san-diego/agents</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250313_001340-s8omzq9z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ilql(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f720bc9b-94fa-4db9-9828-4f94a6403b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Evaluating: gpt2_42_100\n",
      "ILQL CHECKPOINT LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:59<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated: gpt2_42_100\n",
      "Start Evaluating: gpt2-medium_42_100\n",
      "ILQL CHECKPOINT LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:07<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated: gpt2-medium_42_100\n",
      "Start Evaluating: gpt2-large_42_100\n",
      "ILQL CHECKPOINT LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated: gpt2-large_42_100\n",
      "Start Evaluating: gpt2-xl_42_100\n",
      "ILQL CHECKPOINT LOADED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:40<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated: gpt2-xl_42_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_evaluations(config, filtered_eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1193d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variance_by_turn': {0: 0.7506887267056481,\n",
       "  1: 3.0827336093902113,\n",
       "  2: 3.991752503770039,\n",
       "  3: 4.541182183367169,\n",
       "  4: 4.726416334320138,\n",
       "  5: 4.598426892908739,\n",
       "  6: 4.513711400745505,\n",
       "  7: 4.253859160601736,\n",
       "  8: 4.049204411483638,\n",
       "  9: 3.900609631599493,\n",
       "  10: 3.7932281815596096,\n",
       "  11: 3.7300817876877868,\n",
       "  12: 3.6663655050961603,\n",
       "  13: 3.631174634382329,\n",
       "  14: 3.5915843489278894,\n",
       "  15: 3.5693184446837556,\n",
       "  16: 3.585712945475949,\n",
       "  17: 3.546538530571067,\n",
       "  18: 3.545031387282631},\n",
       " 'agreement_by_turn': {0: 0.3866666666666631,\n",
       "  1: 0.3546666666666644,\n",
       "  2: 0.34084836339345187,\n",
       "  3: 0.3991228070175414,\n",
       "  4: 0.4617597292724178,\n",
       "  5: 0.4789311408016436,\n",
       "  6: 0.48813263525305356,\n",
       "  7: 0.4930851063829785,\n",
       "  8: 0.4956568946796959,\n",
       "  9: 0.496111111111111,\n",
       "  10: 0.4979023646071701,\n",
       "  11: 0.49664694280078886,\n",
       "  12: 0.4975698663426487,\n",
       "  13: 0.49584889995848896,\n",
       "  14: 0.49724342663273957,\n",
       "  15: 0.49583333333333324,\n",
       "  16: 0.49303683737646,\n",
       "  17: 0.4944751381215468,\n",
       "  18: 0.49285714285714277}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cross_run_metrics(\"./evaluation_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bd706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
